#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Mar 23 09:03:43 2022

@author: marcorax93
"""

import numpy as np
import copy
from joblib import Parallel, delayed 

class MIG_Layer:
    """
    Mutual Information Gate Layer for GORDONN architecture, used to subsample 
    clusters in the network by keeping only informative clusters. This allow
    to remove events based on the amount of information that they relay about
    the classification task. The MI is calculated for the clusters of the 
    previous layer, clusters are sorted by MI information and only the best
    clusters that amount to the MI_factor are kept. The events associated 
    with the least informative clusters are then discarted by the method
    .predict()
    
    MIG Layer constructor arguments: 
    
    n_input_channels (int): the total number of channels of the previous layer.   
        
    n_input_features (int): the total number of features of the previous layer.   
    
    MI_factor (int): the percent of total mutual information that is kept by 
                     the layer.  
                     
    n_threads (int) : The network can compute the recordings in parallel, 
                      this arguments defines the number of simultaneous threads
 
    verbose (boolean) : If True, the layer will output messages to inform the 
                          the users about the current states as well as plots.                                             

    """
    def __init__(self, n_input_channels, n_input_features, MI_factor=95,
                 n_threads=8, verbose=False):
        
        self.n_input_channels = n_input_channels
        self.n_input_features = n_input_features
        self.MI_factor = MI_factor
        self.n_threads = n_threads
        self.verbose = verbose


    def learn(self, layer_dataset, labels): #TODO add visualization here
        """
        Method to calculate the MI for each feature in a dataset. 
        
        Arguments: 
             layer_dataset: list of individual event based recoriding as
                            generated by the cochlea
                            
             labels: list of labels index of each recording of layer_dataset
        """
        
        n_recordings = len(layer_dataset)
        n_features = self.n_input_features 
        n_labels = max(labels)+1

        hists, norm_hists = histogram_generation(layer_dataset, 
                                                 self.n_input_features,
                                                 self.n_input_channels)
        
        norm_hists = np.sum(norm_hists,1)
        n_bins = int(1e3)#number of bins used to approximate pdf of Response
        max_response = np.max(norm_hists)
        binsize = max_response/n_bins        
        
        norm_hists_binned = np.asarray(norm_hists//binsize, dtype=int)# Maybe try fractional bins
        # norm_hists_binned+=1
        # norm_hists_binned[norm_hists==0]=0
        max_rate = np.max(norm_hists_binned)
        
        r_s_table = np.zeros([max_rate, n_labels, n_features])
        
        for rate in range(max_rate):
            for label in range(n_labels):
                label_indx = labels==label
                rate_pos=norm_hists_binned[label_indx]==rate
                r_s_table[rate,label] = np.sum(rate_pos,axis=0)
            
        p_r = np.sum(r_s_table,axis=1)/n_recordings
            
        # Entropy of label
        H_s = np.log2(n_labels)
                
        
        featMI = np.zeros(n_features)+H_s
        for rate in range(max_rate):
            for i_feat in range(n_features):
                p_x = p_r[rate, i_feat]
                #probability of all labels conditioned to the on cluster
                p_s_x = r_s_table[rate,:,i_feat]/sum(r_s_table[rate,:,i_feat]+1e-9)
                # p_s_off = 1-p_s_on
                H_s_x = -p_s_x*np.log2(p_s_x+1e-9)#to avoid zero log
                H_s_r = p_x*sum(H_s_x) 
                featMI[i_feat] -= H_s_r
        
        
        # Sort the features by MI
        # featMI = np.sum(MI, axis=0)
        sortfeats = np.argsort(featMI)[::-1]
        featMI = featMI[sortfeats]
        cumMI = (np.cumsum(featMI)/sum(featMI))*100
        
        topfeats = sortfeats[cumMI<=self.MI_factor]
        
        self.sortfeats = sortfeats
        self.featMI = featMI
        self.topfeats = topfeats
        
        # Output arguments for next layers
        self.n_output_channels = self.n_input_channels
        self.n_output_features = len(topfeats)
        

        
    def learn_old(self, layer_dataset, labels):
        """
        Method to calculate the MI for each feature in a dataset. 
        
        Arguments: 
             layer_dataset: list of individual event based recoriding as
                            generated by the cochlea
                            
             labels: list of labels index of each recording of layer_dataset
        """
        
        n_recordings = len(layer_dataset)
        n_features = self.n_input_features 
        n_labels = max(labels)+1
        
        # The MI calculated here is binary a feature is either present in a 
        # a recording or not
        activity = np.zeros([n_recordings, n_features])
        for recording in range(n_recordings): 
            if len(layer_dataset[recording][-1]):
                features = np.unique(layer_dataset[recording][-1])
                activity[recording, features]=1;
            
        p_r_s = np.zeros([n_labels, n_features])
        r_s_table = np.zeros([n_labels, n_features])
        p_s = 1/n_labels
        p_r = np.sum(activity,axis=0)/(n_recordings) #all recordings since a cluster
                                                     #can potentially be present in any of them
        p_not_r = 1-p_r
        
        for label in range(n_labels):
            indx = labels==label
            p_r_s[label]+=np.sum(activity[indx,:],axis=0)/sum(labels==label)
            r_s_table[label] += np.sum(activity[indx,:],axis=0)
        
        p_not_r_s = 1-p_r_s
        #number of recordings is the same per each label.
        # p_r = p_r/(n_recordings*number_of_labels)
        
        
        # MI_cluster_on = p_r_s*np.log2(p_r_s/((p_r)+np.logical_not(p_r)) + np.logical_not(p_r_s))
        # MI_cluster_off = p_not_r_s*np.log2(p_not_r_s/((p_not_r)+np.logical_not(p_not_r)) + np.logical_not(p_not_r_s))
        
        # MI = p_s*(MI_cluster_on+MI_cluster_off)
        
        # Entropy of label
        H_s = np.log2(n_labels)
        
        featMI = np.zeros(n_features)
        for i_feat in range(n_features):
            #probability of the cluster being on
            p_on = p_r[i_feat]
            p_off = 1-p_on
            #probability of all labels conditioned to the on cluster
            p_s_on = r_s_table[:,i_feat]/sum(r_s_table[:,i_feat])
            p_s_off = 1-p_s_on
            H_s_on = -p_s_on*np.log2(p_s_on+1e-9)#to avoid zero log
            H_s_off = -p_s_off*np.log2(p_s_off+1e-9)#to avoid zero log
            H_s_r = p_on*sum(H_s_on) + p_off*sum(H_s_off)
            featMI[i_feat] = H_s - H_s_r
        
        # Sort the features by MI
        # featMI = np.sum(MI, axis=0)
        sortfeats = np.argsort(featMI)[::-1]
        featMI = featMI[sortfeats]
        cumMI = (np.cumsum(featMI)/sum(featMI))*100
        
        topfeats = sortfeats[cumMI<=self.MI_factor]
        
        self.sortfeats = sortfeats
        self.featMI = featMI
        self.topfeats = topfeats
        
        # Output arguments for next layers
        self.n_output_channels = self.n_input_channels
        self.n_output_features = len(topfeats)

        
    def predict(self, layer_dataset, labels):
        """
        Method to remove the least indormative features/events
        
        Arguments: 
             layer_dataset: list of individual event based recoriding as
                            generated by the cochlea
            
             labels: list of labels index of each recording of layer_dataset
             
             Returns: 
                 MIG_response: list of individual event based recordings,
                               pruned by removing the least informative events

        """
        
        if self.verbose:
            par_verbose = 0
        else:
            par_verbose = 0
        
        MIG_response = Parallel(n_jobs=self.n_threads, verbose=par_verbose)\
                            (delayed(feature_events_pruning)\
                            (layer_dataset[recording], self.topfeats)
                          for recording in range(len(layer_dataset)))

        return MIG_response


    
    #Importing Classifiers Methods
    from Libs.GORDONN.Classifiers.Histogram_Classifiers import gen_histograms
    from Libs.GORDONN.Classifiers.Histogram_Classifiers import gen_signatures



def feature_events_pruning(rec_data, feature_idxs):
    """
    This function is used to remove all events in a recording that have an 
    index different from indexes present in feature_idxs (a list of indexes).
    It returns the same rec data with a new set reassigned indexes for the
    remaining events (to avoid missing cluster indexes)
    """
    
    n_data_dim = len(rec_data)
    n_events = len(rec_data[0])
    f_index_data = rec_data[-1]
    new_rec_data = [[] for i in range(n_data_dim)] 
    
    if n_events:
        new_f_index_data = -1*np.ones(n_events, dtype=int)
        sort_feature_idxs = np.sort(feature_idxs)
        for i_index, f_index in enumerate(sort_feature_idxs):
            new_f_index_data[f_index_data==f_index]=i_index
        
        relevant_ev_indxs = new_f_index_data>-1
        
        for data_dim in range(n_data_dim-1):
            new_rec_data[data_dim]=rec_data[data_dim][relevant_ev_indxs]
        
        new_rec_data[-1]=new_f_index_data[relevant_ev_indxs]   
        
    
    return new_rec_data
        
def histogram_generation(neuro_response, n_input_features, n_input_channels):
    """
    Function used to generate histograms of a neuromorphic layer response.
    """
    n_recordings = len(neuro_response)
        
    hists = np.zeros([n_recordings, n_input_channels, n_input_features])
    norm_hists = np.zeros([n_recordings, n_input_channels, n_input_features])
    for recording_i,data in enumerate(neuro_response):
        if len(data[0]):
            data = data[1:] #discarding the timestamp information
            indx, occurences = np.unique(data, axis=1, return_counts=True)
            indx = np.asarray(indx, dtype=(int))
            if n_input_channels==None:
                hists[recording_i,0,indx[0]] = occurences
                norm_hists[recording_i,0,indx[0]] = occurences/sum(occurences)
            elif n_input_features==None:
                hists[recording_i,indx[0],0] = occurences
                norm_hists[recording_i,indx[0],0] = occurences/sum(occurences)
            else:
                hists[recording_i,indx[0],indx[1]] = occurences
                norm_hists[recording_i,indx[0],indx[1]] = occurences/sum(occurences)
            

    return hists, norm_hists    