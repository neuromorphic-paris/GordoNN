#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Mar 23 09:03:43 2022

@author: marcorax93
"""

import numpy as np
import time
from joblib import Parallel, delayed 
from sklearn.cluster import  MiniBatchKMeans
import matplotlib.pyplot as plt


class Cross_Layer:
    """
    Cross Layer for GORDONN architecture, used to detect temporal patterns in 
    single channels of the neuromorphic cochlea. It can also be used as an 
    initial layer with specific taus per channel
    
    Cross Layer constructor arguments: 
        
    n_features (int) : the number of features or centers extracted by the 
                       local layer.
                       
    cross_tv_width (int): the width of the cross time vectors across channels,
                          polarity, if set to None the vector always spans across 
                          all the available channels, and it is not centered
                          on the reference event anymore. IF NUMBER
                          IT HAS TO BE ODD
    
    taus (float):  a list containing the time coefficient 
                   used for the local time vector creations 
                   for each channel of the cochlea, if it is
                   a single float, all channels/polarities
                   will have the same tau.
                   
    n_input_channels (int): the total number of channels or polarities of the 
                           previous layer.
                                                      
    
    n_input_features (int): the number of features of the previous layer, None,
                            if the previous layer didn't have any features 
                            (cochlea output)
    
    n_batch_files (int): the number of files processed for a single batch of 
                         learning/infering. If None or > than the number of files
                         in the dataset, data will be processed in a single run.
                         Clustering is performed bua minibatch_kmeans, if number
                         of batches >1 the quality of clustering might be worse.
                            
    dataset_runs (int): the number of runs for a single dataset, if data is run 
                        in a single batch, this parameter will be authomatically
                        set to 1.
    
    n_threads (int) : The network can compute timevectors in a parallel way,
                    this parameter set the number of the parallel jobs that 
                    it can use.
 
    verbose (boolean) : If True, the layer will output messages to inform the 
                          the users about the current states as well as plots.
    """
    def __init__(self, n_features, cross_tv_width, taus, n_input_channels, 
                 n_input_features=None, n_batch_files=None, dataset_runs=1,
                 n_threads=8, verbose=False):
        
        self.n_features = n_features
        self.cross_tv_width = cross_tv_width
        self.taus = taus
        self.n_input_channels = n_input_channels
        self.n_input_features = n_input_features
        self.n_batch_files = n_batch_files
        self.dataset_runs = dataset_runs
        self.n_threads = n_threads
        self.verbose = verbose
        
        # Output arguments for next layers
        self.n_output_features = n_features
        #Output channels is calculated only after training
        
    def learn(self, layer_dataset, labels):
        """
        Method to process and learn cross features.
        Since datasets can be memory intensive to process this method works 
        with minibatch clustering, if the number of batch per files 
        
        Arguments: 
             layer_dataset: list of individual event based recoriding as
                            generated by the cochlea
                            
             labels: list of labels index of each recording of layer_dataset
                            
        """
        
        # Build the vector of individual taus
        if type(self.taus) is np.ndarray or type(self.taus) is list :
            taus = np.array(self.taus)
        else:
            taus = self.taus*np.ones(self.n_input_channels)
            
        # Check the runtime mode (multiple batches or single batch)
        n_files = len(layer_dataset)
        
        if self.n_batch_files==None:
            n_batches = 1
            n_runs = 1
            n_batch_files = n_files
        else:
            n_batch_files = self.n_batch_files
            # number of batches per run   
            n_batches=int(np.ceil(n_files/n_batch_files))  
        
        if n_batches==1:
            n_runs = 1
        else:
            n_runs = self.dataset_runs # how many time a single dataset get cycled.
        
        total_batches  = n_batches*n_runs
        
        #Check if it is in convolutional mode or not
        if self.cross_tv_width == None or self.cross_tv_width >= self.n_input_channels :
            #Full layer
            cross_width = self.n_input_channels
            self.conv = False
        else:
            #Convolutional mode
            cross_width = self.cross_tv_width
            self.conv = True
        
        #Check if previous layer had features or not
        if self.n_input_features == None:
            n_input_features = 1
        else:
            n_input_features = self.n_input_features
            
        
        #Set the verbose parameter for the parallel function. #TODO set outside layer
        if self.verbose:
            par_verbose = 0
           # print('\n--- LAYER '+str(layer)+' CROSS TIME VECTORS LEARNING ---')
            batch_start_time = time.time()
            total_time = batch_start_time-batch_start_time
        else:
            par_verbose = 0
          
        kmeans = MiniBatchKMeans(n_clusters=self.n_features,
                                 verbose=par_verbose)
        
        kmeans._n_threads = self.n_threads
        
        for run in range(n_runs):    
            for i_batch_run in range(n_batches):
                
                cross_batch_tv = self.batch_tv_generator(layer_dataset,
                                                         n_batch_files,
                                                         i_batch_run, 
                                                         par_verbose)
          
            
                # The final results of the local surfaces train dataset computation
                cross_batch_tv = np.concatenate(cross_batch_tv, axis=0)
                
                if n_batches==1:
                    kmeans.fit(cross_batch_tv)
                else:
                    kmeans.partial_fit(cross_batch_tv)
                
                if self.verbose is True: 
                    batch_time = time.time()-batch_start_time
                    i_batch = i_batch_run + n_batches*run                    
                    expected_t = batch_time*(total_batches-i_batch-1)
                    total_time += (time.time() - batch_start_time)
                    print("Batch %i out of %i processed, %s seconds left "\
                          %(i_batch+1,total_batches,expected_t))                
                    batch_start_time = time.time()
            

        if self.verbose is True:    
            print("learning time vectors took %s seconds." % (total_time))
            
        self.features = kmeans.cluster_centers_
        #TODO add a calculation for featues after removing zero pad
        if self.conv:
            self.n_output_channels = self.n_input_channels
        else:
            self.n_output_channels = None
            
    def predict(self, layer_dataset, labels):
        """
        Method to generate cross features response.
        Since datasets can be memory intensive to process this method works 
        with minibatch clustering, if the number of batch per files 
        
        Arguments: 
            layer_dataset: list of individual event based recoriding as
                           generated by the cochlea
                           
            labels: list of labels index of each recording of layer_dataset
                          
        Returns: 
            cross_response: list of individual event based recordings with a
                            new array of the corresponfing feature index
                            per each event. Any eventual previous feature
                            array is removed.
        """
        

            
        # Check the runtime mode (multiple batches or single batch)
        n_files = len(layer_dataset)
        
        if self.n_batch_files==None:
            n_batches = 1
            n_batch_files = n_files
        else:
            n_batch_files = self.n_batch_files
            # number of batches per run   
            n_batches=int(np.ceil(n_files/n_batch_files))  
        
        total_batches  = n_batches
        
        #Set the verbose parameter for the parallel function. #TODO set outside layer
        if self.verbose:
            par_verbose = 0
           # print('\n--- LAYER '+str(layer)+' CROSS TIME VECTORS LEARNING ---')
            batch_start_time = time.time()
            total_time = batch_start_time-batch_start_time
        else:
            par_verbose = 0
          
        kmeans = MiniBatchKMeans(n_clusters=self.n_features,
                                 verbose=par_verbose)
        
        kmeans._n_threads = self.n_threads
        kmeans.cluster_centers_ = self.features
        
        cross_response=[]
        for i_batch_run in range(n_batches):
            
            cross_batch_tv = self.batch_tv_generator(layer_dataset,
                                                     n_batch_files,
                                                     i_batch_run, 
                                                     par_verbose)
            
            cross_batch_response = self.batch_response_generator(layer_dataset,
                                                                 cross_batch_tv,
                                                                 n_batch_files,
                                                                 i_batch_run, 
                                                                 kmeans)
            
            cross_response = cross_response+cross_batch_response
            
            if self.verbose is True: 
                batch_time = time.time()-batch_start_time
                i_batch = i_batch_run                     
                expected_t = batch_time*(total_batches-i_batch-1)
                total_time += (time.time() - batch_start_time)
                print("Batch %i out of %i processed, %s seconds left "\
                      %(i_batch+1,total_batches,expected_t))                
                batch_start_time = time.time()
    
        if self.verbose is True:    
            print("generatung time vectors took %s seconds." % (total_time))
            
        return cross_response 
        
    def batch_tv_generator(self, layer_dataset, n_batch_files, i_batch_run, 
                           par_verbose):
        """
        Method to make the layer generate a single batch of time-vectors, can be
        used by the predict method or the neural network method, to speedup 
        computation and reduce memory usage
        
        Arguments: 
            layer_dataset: list of individual event based recoriding as
                           generated by the cochlea
                           
                          
        Returns: 
            cross_batch_tv: list of individual timevectores produced from 
                                  from a single batch.       
        """
        # Build the vector of individual taus
        if type(self.taus) is np.ndarray or type(self.taus) is list :
            taus = np.array(self.taus)
        else:
            taus = self.taus*np.ones(self.n_input_channels)
            
        #Check if it is in convolutional mode or not
        if self.cross_tv_width == None or self.cross_tv_width >= self.n_input_channels :
            #Full layer
            cross_width = self.n_input_channels
            self.conv = False
        else:
            #Convolutional mode
            cross_width = self.cross_tv_width
            self.conv = True
        
        #Check if previous layer had features or not
        if self.n_input_features == None:
            n_input_features = 1
        else:
            n_input_features = self.n_input_features
        
        rec_ind_1 = i_batch_run*n_batch_files
        rec_ind_2 = (i_batch_run+1)*n_batch_files
        
        data_subset = layer_dataset[rec_ind_1:rec_ind_2]
        
        # check if it is a convolutional layer.
        if self.conv:
            
            #Generation of cross surfaces, computed on multiple threads
            cross_batch_tv = Parallel(n_jobs=self.n_threads, verbose=par_verbose)\
                                (delayed(cross_tv_generator_conv)\
                                (data_subset[recording], 
                                  self.n_input_channels,\
                                  n_input_features, cross_width,\
                                  taus)\
                              for recording in range(len(data_subset)))
        
      
        
        
        else:
                          
            #Generation of cross surfaces, computed on multiple threads
            cross_batch_tv = Parallel(n_jobs=self.n_threads, verbose=par_verbose)\
                                (delayed(cross_tv_generator)\
                                (data_subset[recording], 
                                  self.n_input_channels,\
                                  n_input_features,taus)\
                              for recording in range(len(data_subset)))
                                          

    
        return cross_batch_tv  
    
    def batch_response_generator(self, layer_dataset, cross_batch_tv, 
                                       n_batch_files, i_batch_run, kmeans):
        """
        Method to make the layer generate a single batch of time-vectors, can be
        used by the predict method or the neural network method, to speedup 
        computation and reduce memory usage
        
        Arguments: 
            layer_dataset: list of individual event based recoriding as
                           generated by the cochlea
                           
                          
        Returns: 
            cross_batch_response: list of individual timevectores produced from 
                                  from a single batch.       
        """
        
        
        
        rec_ind_1 = i_batch_run*n_batch_files
        rec_ind_2 = (i_batch_run+1)*n_batch_files
        
        data_subset = layer_dataset[rec_ind_1:rec_ind_2]
        
        cross_batch_response=[]
        # check if it is a convolutional layer.
        if self.conv:
            
        
            for i_result in range(len(cross_batch_tv)):
                if len(cross_batch_tv[i_result]):
                    batch_response=kmeans.predict(cross_batch_tv[i_result])
                    cross_batch_response.append([data_subset[i_result][0],\
                                           data_subset[i_result][1],\
                                               batch_response])
                else:
                    cross_batch_response.append([[],[],[]])
        
        
        
        else:
                          
                                    
            for i_result in range(len(cross_batch_tv)):
                batch_response=kmeans.predict(cross_batch_tv[i_result])
                cross_batch_response.append([data_subset[i_result][0],\
                                       batch_response])
        

    
        return cross_batch_response 
    
    
    #Importing Classifiers Methods
    from Libs.GORDONN.Classifiers.Histogram_Classifiers import gen_histograms
    from Libs.GORDONN.Classifiers.Histogram_Classifiers import gen_signatures
    from Libs.GORDONN.Classifiers.Time_Vector_Classifiers import train_mlp
    from Libs.GORDONN.Classifiers.Time_Vector_Classifiers import test_mlp

    
    #TODO obtain the original channel of the event
    def response_plot(self, cross_response, f_index, class_name = None):
        """
        Function used to generate plots of cross layer response.
        It Plots the input data first, and the scatter plot of events 
        colored by feature index.
        """
        
        timestamps = cross_response[f_index][0]
        channels =  cross_response[f_index][1]
        features = cross_response[f_index][2]
        
        # First print the original recording
        plt.figure()
        plt.suptitle('Original file: '+ str(f_index) +' Class: '+ str(class_name), fontsize=16)
        plt.scatter(timestamps, channels, s=1)
   
        plt.figure()
        for i_feature in range(self.n_features):
            # Extract events by feature
            indx = features==i_feature
    
            image = plt.scatter(timestamps[indx], channels[indx],\
                                label='Feature '+str(i_feature))

    

    
    
def cross_tv_generator(recording_data, n_polarities, features_number, taus):
    """
    Function used to generate cross time vectors.
    
    Arguments:
        
        recording_data (list of 2 numpy 1D arrays): It consists of the time stamps 
                        and polarity indeces for all the events of a single 
                        recording.
                        
        n_polarities (int): the number of channels/polarities of the dataset.
        features_number (int): the number of features of the previous layer
        taus (array of floats): the single decays of the cross time vector layer
                               per channel.
        context_length (int): the length of the cross time vector 
                              (the length of its context).  
    
    Returns:
        
        cross_tvs (2D numpy array of floats): the timevectors generated for the 
                   recording where the dimensions are [i_event, flattened 
                                                       2D timesurface element]
    """
    
    
    n_events = len(recording_data[0])
    
    # 2D timesurface dimension
    ydim,xdim = [n_polarities, features_number]
    cross_tvs = np.zeros([len(recording_data[0]),xdim*ydim], dtype="float16")
    timestamps = np.zeros([ydim, xdim], dtype=int)
    
    # create a taus matrix with the tiling taus to the size of timestamp
    taus_m = np.transpose(np.tile(taus,[xdim,1]))
    
    if features_number>1:
        features = recording_data[2]
    else:
        features = np.zeros(n_events, dtype=int)
        
    for event_ind in range(n_events):   
        new_timestamp = recording_data[0][event_ind]                                   
        polarity = recording_data[1][event_ind]
        feature = features[event_ind]
        timestamps[polarity, feature] = recording_data[0][event_ind]
        timesurf = np.exp(-(new_timestamp-timestamps)/taus_m)*(timestamps!=0)   
        cross_tvs[event_ind] = (timesurf).flatten() 


    return cross_tvs


    

                
def cross_tv_generator_conv(recording_data, n_polarities, features_number, 
                            cross_width, taus):
    """
    Function used to generate cross time vectors.
    
    Arguments:
        
        recording_data: (list of 2 numpy 1D arrays) It consists of the time stamps 
                        and polarity indeces for all the events of a single 
                        recording.
                        
        n_polarities: (int) the number of channels/polarities of the dataset.
        features_number (int): the number of features of the previous layer
        cross_width (int): the lateral size of the cross time vector.
        taus (array of floats): the single decays of the cross time vector layer
                               per channel/polarity. 
    
    Returns:
        
        cross_tvs (2D numpy array of floats): the timevectors generated for the 
                   recording where the dimensions are [i_event, flattened 
                                                       2D timevector element]
    """
    
    
    n_events = len(recording_data[0])
    
    # 2D timesurface dimension
    ydim,xdim = [n_polarities, features_number]
    cross_tvs_conv = np.zeros([len(recording_data[0]),cross_width*xdim], dtype="float16")
    zerp_off =  cross_width//2#zeropad offset
    timestamps = np.zeros([ydim+zerp_off*2, xdim], dtype=int) # ydim + 2* zeropad
    
    # create a taus matrix with the tiling taus to the size of timestamp
    taus_m = np.ones([ydim+zerp_off*2])
    taus_m[zerp_off:-zerp_off] = taus
    taus_m = np.transpose(np.tile(taus_m,[xdim,1]))
    
    if features_number>1:
        features = recording_data[2]
    else:
        features = np.zeros(n_events, dtype=int)
    
    local_ind = np.arange(cross_width)    
    for event_ind in range(n_events):   
        new_timestamp = recording_data[0][event_ind]                                   
        polarity = recording_data[1][event_ind]
        feature = features[event_ind]
        timestamps[polarity+zerp_off, feature] = recording_data[0][event_ind]
        exponent = -(new_timestamp-timestamps)/taus_m
        exponent[exponent<-10] = -10 #To avoid overflow 
        exponent[exponent>0] = 0 #To avoid positive exponentials 
        timesurf = np.exp(exponent)*(timestamps!=0)   
        timesurf = timesurf[local_ind+polarity]
        cross_tvs_conv[event_ind,:] = (timesurf).flatten() 


    return cross_tvs_conv

